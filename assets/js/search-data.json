{
  
    
        "post0": {
            "title": "Title",
            "content": "&#25105;&#30340;&#19968;&#20010;&#23567;&#23454;&#39564; . 本文是基于fast.ai课程内容尝试梳理运用教学内容来利用MNIST数据集实现手写数字0-9的分类器 . &#25968;&#25454;&#38598;&#22788;&#29702; . 首先下载MNIST数据集 . path = untar_data(URLs.MNIST) Path.BASE_PATH = path for o in range(10): locals()[&#39;nums&#39; + str(o)] = (path/&#39;training&#39;/str(o)).ls().sorted() im3 = Image.open(nums3[1]) im3 . 其中，每张图片包含28*28个像素点，可以用灰度来表示： . im3_t = tensor(im3) df = pd.DataFrame(im3_t[3:25,3:25]) df.style.set_properties(**{&#39;font-size&#39;:&#39;6pt&#39;}).background_gradient(&#39;Greys&#39;) . 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 . 0 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 1 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 0 | 0 | 0 | 0 | 0 | 0 | 29 | 150 | 195 | 254 | 255 | 254 | 176 | 193 | 150 | 96 | 0 | 0 | 0 | 0 | 0 | 0 | . 3 0 | 0 | 0 | 0 | 48 | 166 | 224 | 253 | 253 | 234 | 196 | 253 | 253 | 253 | 253 | 233 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 0 | 0 | 93 | 244 | 249 | 253 | 187 | 46 | 10 | 8 | 4 | 10 | 194 | 253 | 253 | 233 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 0 | 0 | 107 | 253 | 253 | 230 | 48 | 0 | 0 | 0 | 0 | 0 | 192 | 253 | 253 | 156 | 0 | 0 | 0 | 0 | 0 | 0 | . 6 0 | 0 | 3 | 20 | 20 | 15 | 0 | 0 | 0 | 0 | 0 | 43 | 224 | 253 | 245 | 74 | 0 | 0 | 0 | 0 | 0 | 0 | . 7 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 249 | 253 | 245 | 126 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 8 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 14 | 101 | 223 | 253 | 248 | 124 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 9 0 | 0 | 0 | 0 | 0 | 0 | 11 | 166 | 239 | 253 | 253 | 253 | 187 | 30 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 10 0 | 0 | 0 | 0 | 0 | 0 | 16 | 248 | 250 | 253 | 253 | 253 | 253 | 232 | 213 | 111 | 2 | 0 | 0 | 0 | 0 | 0 | . 11 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 43 | 98 | 98 | 208 | 253 | 253 | 253 | 253 | 187 | 22 | 0 | 0 | 0 | 0 | . 12 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 9 | 51 | 119 | 253 | 253 | 253 | 76 | 0 | 0 | 0 | 0 | . 13 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 183 | 253 | 253 | 139 | 0 | 0 | 0 | 0 | . 14 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 182 | 253 | 253 | 104 | 0 | 0 | 0 | 0 | . 15 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 85 | 249 | 253 | 253 | 36 | 0 | 0 | 0 | 0 | . 16 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 60 | 214 | 253 | 253 | 173 | 11 | 0 | 0 | 0 | 0 | . 17 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 98 | 247 | 253 | 253 | 226 | 9 | 0 | 0 | 0 | 0 | 0 | . 18 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 42 | 150 | 252 | 253 | 253 | 233 | 53 | 0 | 0 | 0 | 0 | 0 | 0 | . 19 0 | 0 | 0 | 42 | 115 | 42 | 60 | 115 | 159 | 240 | 253 | 253 | 250 | 175 | 25 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 20 0 | 0 | 0 | 187 | 253 | 253 | 253 | 253 | 253 | 253 | 253 | 197 | 86 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 21 0 | 0 | 0 | 103 | 253 | 253 | 253 | 253 | 253 | 232 | 67 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 将所有同数字数据转化为张量组合，对有元素的像素点取1，无元素的取0 . for o in range(10): locals()[&#39;train&#39; + str(o)]=torch.stack([tensor(Image.open(i)) for i in locals()[&#39;nums&#39;+str(o)]]) . for o in range(10): locals()[&#39;train&#39; + str(o)]=locals()[&#39;train&#39; + str(o)].float()/255 . 3&#21644;6 &#20998;&#31867; . 首先我们做一个简单的分类器，它只能分类3和6 . train_x = torch.cat([train3,train6]).view(-1, 28*28) # 用标签1来表示3，用标签0来表示6 train_y = tensor([1]*len(nums3) + [0]*len(nums6)).unsqueeze(1) train_x.shape,train_y.shape . (torch.Size([12049, 784]), torch.Size([12049, 1])) . dset = list(zip(train_x, train_y)) x,y = dset[0] . 接下来处理验证集 . (path/&#39;testing&#39;).ls() . (#10) [Path(&#39;testing/2&#39;),Path(&#39;testing/3&#39;),Path(&#39;testing/6&#39;),Path(&#39;testing/5&#39;),Path(&#39;testing/1&#39;),Path(&#39;testing/7&#39;),Path(&#39;testing/0&#39;),Path(&#39;testing/4&#39;),Path(&#39;testing/8&#39;),Path(&#39;testing/9&#39;)] . valid3 = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;3&#39;).ls()]) valid3 = valid3.float()/255 valid6 = torch.stack([tensor(Image.open(o)) for o in (path/&#39;testing&#39;/&#39;6&#39;).ls()]) valid6 = valid6.float()/255 . valid_x = torch.cat([valid3, valid6]).view(-1, 28*28) valid_y = tensor([1]*len(valid3) + [0]*len(valid6)).unsqueeze(1) valid_dset = list(zip(valid_x, valid_y)) . 生成一个随机的初始化参数矩阵函数： . def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_() . 定义线性函数模型： . def linear1(xb): return xb@weights + bias#&#39;@&#39;表示矩阵乘法运算 # preds = linear1(train_x) . 激活函数： . def sigmoid(x): return 1/(1+torch.exp(-x)) plot_function(torch.sigmoid, title=&#39;Sigmoid&#39;, min=-4,max=4) . /usr/local/lib/python3.7/dist-packages/fastbook/__init__.py:74: UserWarning: Not providing a value for linspace&#39;s steps is deprecated and will throw a runtime error in a future release. This warning will appear only once per process. (Triggered internally at /pytorch/aten/src/ATen/native/RangeFactories.cpp:25.) x = torch.linspace(min,max) . 定义损失函数： . note: torch.where(A,B,C)与三目运算符A?B:C类似 . def mnist_loss(predictions, targets): predictions = predictions.sigmoid() return torch.where(targets==1, 1-predictions, predictions).mean() . 计算梯度： . def calc_grad(xb,yb,model): preds = model(xb) loss = mnist_loss(preds, yb) loss.backward() . 单次训练： . def train_epoch(model, lr, params): for xb,yb in dl: calc_grad(xb, yb, model) for p in params: p.data -= p.grad*lr p.grad.zero_() . 利用验证集进行精确度计算： . def batch_accuracy(xb, yb): preds = xb.sigmoid() correct = (preds&gt;0.5) == yb return correct.float().mean() def validate_epoch(model): accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl] return round(torch.stack(accs).mean().item(), 4) . 试着训练一次： . #初始化参数矩阵 weights = init_params((28*28,1)) bias = init_params(1) #划分数据 dl = DataLoader(dset, batch_size=256) xb,yb = first(dl) valid_dl = DataLoader(valid_dset, batch_size=256) # lr = 1. params = weights,bias train_epoch(linear1, lr, params) validate_epoch(linear1) . 0.7592 . 接下来训练一定次数 . for i in range(20): train_epoch(linear1, lr, params) print(validate_epoch(linear1),end=&#39; &#39;) . 0.8643 0.9375 0.9556 0.9693 0.9756 0.9766 0.9795 0.9805 0.9815 0.982 0.982 0.9844 0.9854 0.9859 0.9859 0.9869 0.9873 0.9883 0.9888 0.9888 . 目前，我们得到了一个准确率为98.88%的一个3、6手写数字分类器 . 我们可以对以上代码进行一下封装： . 首先，可以用pytorch中nn.linear代替我的linear1，同时nn.linear中也提供了初始化参数的功能可以代替init_params . linear_model = nn.Linear(28*28, 1) w,b = linear_model.parameters() . class BasicOptim: def __init__(self,params,lr): self.params,self.lr = list(params),lr def step(self, *args, **kwargs): for p in self.params: p.data -= p.grad.data * self.lr def zero_grad(self, *args, **kwargs): for p in self.params: p.grad = None . 在创建结构体的同时传递参数 . opt = BasicOptim(linear_model.parameters(),lr) . 同时，我们也需要更新单次epoch计算的函数： . def train_epoch(model): for xb,yb in dl: calc_grad(xb, yb,model) opt.step() opt.zero_grad() . 验证函数不需要更新，接下来只需将训练过程打包成一个函数： . def train_model(model, epochs): for i in range(epochs): train_epoch(model) print(validate_epoch(model), end = &#39; &#39;) . 如同之前的操作，再训练一遍： . train_model(linear_model, 20) . 0.4932 0.4932 0.8115 0.9116 0.9546 0.9668 0.9746 0.979 0.9805 0.9849 0.9883 0.9902 0.9907 0.9907 0.9912 0.9912 0.9917 0.9927 0.9932 0.9932 . 再简化亿点： . dls = DataLoaders(dl, valid_dl) learn = Learner(dls,nn.Linear(28*28,1),opt_func=SGD, loss_func=mnist_loss,metrics=batch_accuracy) learn.fit(10,lr=1.) . epoch train_loss valid_loss batch_accuracy time . 0 | 0.625644 | 0.486351 | 0.513211 | 00:00 | . 1 | 0.620780 | 0.485702 | 0.513211 | 00:00 | . 2 | 0.486226 | 0.185635 | 0.852642 | 00:00 | . 3 | 0.191021 | 0.120285 | 0.902947 | 00:00 | . 4 | 0.081811 | 0.065749 | 0.952236 | 00:00 | . 5 | 0.039486 | 0.046254 | 0.964431 | 00:00 | . 6 | 0.022487 | 0.036316 | 0.973577 | 00:00 | . 7 | 0.015364 | 0.029996 | 0.978150 | 00:00 | . 8 | 0.012187 | 0.025531 | 0.979675 | 00:00 | . 9 | 0.010627 | 0.022211 | 0.983740 | 00:00 | . 线性函数好像对目前的情况够用了，但很多时候我们还是需要非线性函数来优化神经网络。 下面试着来添加一个简单的非线性层 . def simple_net(xb): res = xb@w1 + b1 res = res.max(tensor(0.0)) res = res@w2 + b2 return res . 在上面的网络中，我们在两个线性分类器中添加了一个max函数，也即线性整流函数（ReLU），它的函数图像如图所示： . 同时w1,w2,b1,b2可以定义为如下形式，其中w2,b2的规模是由w1,b1决定的 . w1 = init_params((28*28,30)) b1 = init_params(30) w2 = init_params((30,1)) b2 = init_params(1) . 用pytorch实现： . simple_net = nn.Sequential( nn.Linear(28*28,30), nn.ReLU(), nn.Linear(30,1) ) learn = Learner(dls, simple_net, opt_func=SGD, loss_func=mnist_loss,metrics=batch_accuracy) learn.fit(40,0.1) . epoch train_loss valid_loss batch_accuracy time . 0 | 0.372187 | 0.398609 | 0.500508 | 00:00 | . 1 | 0.160306 | 0.236052 | 0.797764 | 00:00 | . 2 | 0.081211 | 0.097800 | 0.942073 | 00:00 | . 3 | 0.047748 | 0.058415 | 0.963923 | 00:00 | . 4 | 0.032466 | 0.042397 | 0.974594 | 00:00 | . 5 | 0.024872 | 0.033800 | 0.978659 | 00:00 | . 6 | 0.020700 | 0.028416 | 0.983740 | 00:00 | . 7 | 0.018145 | 0.024688 | 0.984756 | 00:00 | . 8 | 0.016414 | 0.021938 | 0.987297 | 00:00 | . 9 | 0.015143 | 0.019818 | 0.989329 | 00:00 | . 10 | 0.014149 | 0.018134 | 0.989329 | 00:00 | . 11 | 0.013337 | 0.016768 | 0.990346 | 00:00 | . 12 | 0.012651 | 0.015643 | 0.990854 | 00:00 | . 13 | 0.012060 | 0.014703 | 0.991362 | 00:00 | . 14 | 0.011541 | 0.013910 | 0.991362 | 00:00 | . 15 | 0.011080 | 0.013233 | 0.991870 | 00:00 | . 16 | 0.010666 | 0.012649 | 0.991870 | 00:00 | . 17 | 0.010292 | 0.012141 | 0.992378 | 00:00 | . 18 | 0.009952 | 0.011696 | 0.991870 | 00:00 | . 19 | 0.009642 | 0.011301 | 0.991870 | 00:00 | . 20 | 0.009357 | 0.010950 | 0.992886 | 00:00 | . 21 | 0.009095 | 0.010636 | 0.993394 | 00:00 | . 22 | 0.008853 | 0.010353 | 0.993394 | 00:00 | . 23 | 0.008628 | 0.010098 | 0.993394 | 00:00 | . 24 | 0.008420 | 0.009866 | 0.993902 | 00:00 | . 25 | 0.008226 | 0.009656 | 0.993902 | 00:00 | . 26 | 0.008045 | 0.009464 | 0.993902 | 00:00 | . 27 | 0.007874 | 0.009289 | 0.994411 | 00:00 | . 28 | 0.007714 | 0.009128 | 0.994411 | 00:00 | . 29 | 0.007564 | 0.008981 | 0.994919 | 00:00 | . 30 | 0.007421 | 0.008846 | 0.994919 | 00:00 | . 31 | 0.007286 | 0.008722 | 0.995427 | 00:00 | . 32 | 0.007157 | 0.008607 | 0.995935 | 00:00 | . 33 | 0.007034 | 0.008500 | 0.995427 | 00:00 | . 34 | 0.006918 | 0.008402 | 0.995427 | 00:00 | . 35 | 0.006806 | 0.008310 | 0.994919 | 00:00 | . 36 | 0.006699 | 0.008225 | 0.994919 | 00:00 | . 37 | 0.006597 | 0.008145 | 0.994919 | 00:00 | . 38 | 0.006498 | 0.008071 | 0.994919 | 00:00 | . 39 | 0.006404 | 0.008001 | 0.994919 | 00:00 | . 画个准确率的图： . plt.plot(L(learn.recorder.values).itemgot(2)); . 最终的准确率是： . learn.recorder.values[-1][2] . 0.994918704032898 .",
            "url": "https://jarvismao.github.io/myblog/2021/09/13/%E8%AF%95%E7%9D%80%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E5%88%86%E7%B1%BB%E5%99%A8.html",
            "relUrl": "/2021/09/13/%E8%AF%95%E7%9D%80%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E5%88%86%E7%B1%BB%E5%99%A8.html",
            "date": " • Sep 13, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://jarvismao.github.io/myblog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://jarvismao.github.io/myblog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://jarvismao.github.io/myblog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jarvismao.github.io/myblog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}